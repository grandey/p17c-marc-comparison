{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis_cdo_nco_draft2017b.ipynb\n",
    "\n",
    "## Purpose\n",
    "Use CDO and NCO to analyse CESM simulation output from project [p17c-marc-comparison](https://github.com/grandey/p17c-marc-comparison).\n",
    "\n",
    "## Requirements\n",
    "- Climate Data Operators (CDO)\n",
    "- NetCDF Operators (NCO)\n",
    "- CESM output data, post-processed to time-series format, as described in [data_management.org](https://github.com/grandey/p17c-marc-comparison/blob/master/manage_data/data_management.org#syncing-to-local-machine-for-analysis). These data will also be uploaded to figshare.\n",
    "\n",
    "## Author\n",
    "Benjamin S. Grandey, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDO and NCO version information\n",
    "Useful to records for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate Data Operators version 1.9.1 (http://mpimet.mpg.de/cdo)\n",
      "Compiled: by root on squall2.local (x86_64-apple-darwin17.2.0) Nov  2 2017 18:28:19\n",
      "CXX Compiler: /usr/bin/clang++ -std=gnu++11 -pipe -Os -stdlib=libc++ -arch x86_64  -D_THREAD_SAFE -pthread\n",
      "CXX version : unknown\n",
      "C Compiler: /usr/bin/clang -pipe -Os -arch x86_64  -D_THREAD_SAFE -pthread\n",
      "C version : unknown\n",
      "Features: DATA PTHREADS HDF5 NC4/HDF5 OPeNDAP SZ UDUNITS2 PROJ.4 CURL FFTW3 SSE4_1\n",
      "Libraries: HDF5/1.10.1 proj/4.93 curl/7.56.1\n",
      "Filetypes: srv ext ieg grb1 nc1 nc2 nc4 nc4c nc5 \n",
      "     CDI library version : 1.9.1 of Nov  2 2017 18:27:49\n",
      " CGRIBEX library version : 1.9.0 of Sep 29 2017 10:16:02\n",
      "  NetCDF library version : 4.4.1.1 of Oct  6 2017 14:14:42 $\n",
      "    HDF5 library version : 1.10.1\n",
      " SERVICE library version : 1.4.0 of Nov  2 2017 18:27:47\n",
      "   EXTRA library version : 1.4.0 of Nov  2 2017 18:27:46\n",
      "     IEG library version : 1.4.0 of Nov  2 2017 18:27:46\n",
      "    FILE library version : 1.8.3 of Nov  2 2017 18:27:46\n",
      "\n",
      "NCO netCDF Operators version 4.6.6 built by root on squall2.local at Nov  3 2017 12:13:40\n",
      "ncks version 4.6.6\n"
     ]
    }
   ],
   "source": [
    "! cdo --version\n",
    "! ncks --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory information for input and output NetCDF files\n",
    "The data in the input directory (*in_dir*) have been synced to the local machine (see [data_management.org](https://github.com/grandey/p17c-marc-comparison/blob/master/manage_data/data_management.org#syncing-to-local-machine-for-analysis)). These data will also be uploaded to figshare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data directory\n",
    "in_dir = os.path.expandvars('$HOME/data/projects/p17c_marc_comparison/output_timeseries/')\n",
    "\n",
    "# Output data directory\n",
    "out_dir = os.path.expandvars('$HOME/data/projects/p17c_marc_comparison/analysis_cdo_nco_draft2017b/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean output data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  6 16:31:09 +08 2017\r\n"
     ]
    }
   ],
   "source": [
    "for filename in glob('{}/*.nc'.format(out_dir)):\n",
    "    print('Deleting {}'.format(filename.split('/')[-1]))\n",
    "    os.remove(filename)\n",
    "for filename in glob('{}/*.nco'.format(out_dir)):\n",
    "    print('Deleting {}'.format(filename.split('/')[-1]))\n",
    "    os.remove(filename)\n",
    "for filename in glob('{}/*.tmp'.format(out_dir)):\n",
    "    print('Deleting {}'.format(filename.split('/')[-1]))\n",
    "    os.remove(filename)\n",
    "! date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate annual means of standard 2D atmosphere variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUL_LDG, marc, 1850\n",
      "  Written marc_1850_SUL_LDG_ANN.nc\n",
      "SUL_LDG, marc, 2000\n",
      "  Written marc_2000_SUL_LDG_ANN.nc\n",
      "pSUL_LDG, marc, 1850\n",
      "  Written marc_1850_pSUL_LDG_ANN.nc\n",
      "pSUL_LDG, marc, 2000\n",
      "  Written marc_2000_pSUL_LDG_ANN.nc\n",
      "OC_LDG, marc, 1850\n",
      "  Written marc_1850_OC_LDG_ANN.nc\n",
      "OC_LDG, marc, 2000\n",
      "  Written marc_2000_OC_LDG_ANN.nc\n",
      "BC_LDG, marc, 1850\n",
      "  Written marc_1850_BC_LDG_ANN.nc\n",
      "BC_LDG, marc, 2000\n",
      "  Written marc_2000_BC_LDG_ANN.nc\n",
      "MOS_LDG, marc, 1850\n",
      "  Written marc_1850_MOS_LDG_ANN.nc\n",
      "MOS_LDG, marc, 2000\n",
      "  Written marc_2000_MOS_LDG_ANN.nc\n",
      "MBS_LDG, marc, 1850\n",
      "  Written marc_1850_MBS_LDG_ANN.nc\n",
      "MBS_LDG, marc, 2000\n",
      "  Written marc_2000_MBS_LDG_ANN.nc\n",
      "BURDENSO4, mam3, 1850\n",
      "  Written mam3_1850_BURDENSO4_ANN.nc\n",
      "BURDENSO4, mam3, 2000\n",
      "  Written mam3_2000_BURDENSO4_ANN.nc\n",
      "BURDENSO4, mam7, 2000\n",
      "  Written mam7_2000_BURDENSO4_ANN.nc\n",
      "BURDENPOM, mam3, 1850\n",
      "  Written mam3_1850_BURDENPOM_ANN.nc\n",
      "BURDENPOM, mam3, 2000\n",
      "  Written mam3_2000_BURDENPOM_ANN.nc\n",
      "BURDENPOM, mam7, 2000\n",
      "  Written mam7_2000_BURDENPOM_ANN.nc\n",
      "BURDENBC, mam3, 1850\n",
      "  Written mam3_1850_BURDENBC_ANN.nc\n",
      "BURDENBC, mam3, 2000\n",
      "  Written mam3_2000_BURDENBC_ANN.nc\n",
      "BURDENBC, mam7, 2000\n",
      "  Written mam7_2000_BURDENBC_ANN.nc\n",
      "TAU_tot, marc, 1850\n",
      "  Written marc_1850_TAU_tot_ANN.nc\n",
      "TAU_tot, marc, 2000\n",
      "  Written marc_2000_TAU_tot_ANN.nc\n",
      "AEROD_v, mam3, 1850\n",
      "  Written mam3_1850_AEROD_v_ANN.nc\n",
      "AEROD_v, mam3, 2000\n",
      "  Written mam3_2000_AEROD_v_ANN.nc\n",
      "AEROD_v, mam7, 2000\n",
      "  Written mam7_2000_AEROD_v_ANN.nc\n",
      "CDNUMC, marc, 1850\n",
      "  Written marc_1850_CDNUMC_ANN.nc\n",
      "CDNUMC, marc, 2000\n",
      "  Written marc_2000_CDNUMC_ANN.nc\n",
      "CDNUMC, mam3, 1850\n",
      "  Written mam3_1850_CDNUMC_ANN.nc\n",
      "CDNUMC, mam3, 2000\n",
      "  Written mam3_2000_CDNUMC_ANN.nc\n",
      "CDNUMC, mam7, 2000\n",
      "  Written mam7_2000_CDNUMC_ANN.nc\n",
      "CLDTOT, marc, 1850\n",
      "  Written marc_1850_CLDTOT_ANN.nc\n",
      "CLDTOT, marc, 2000\n",
      "  Written marc_2000_CLDTOT_ANN.nc\n",
      "CLDTOT, mam3, 1850\n",
      "  Written mam3_1850_CLDTOT_ANN.nc\n",
      "CLDTOT, mam3, 2000\n",
      "  Written mam3_2000_CLDTOT_ANN.nc\n",
      "CLDTOT, mam7, 2000\n",
      "  Written mam7_2000_CLDTOT_ANN.nc\n",
      "CLDLOW, marc, 1850\n",
      "  Written marc_1850_CLDLOW_ANN.nc\n",
      "CLDLOW, marc, 2000\n",
      "  Written marc_2000_CLDLOW_ANN.nc\n",
      "CLDLOW, mam3, 1850\n",
      "  Written mam3_1850_CLDLOW_ANN.nc\n",
      "CLDLOW, mam3, 2000\n",
      "  Written mam3_2000_CLDLOW_ANN.nc\n",
      "CLDLOW, mam7, 2000\n",
      "  Written mam7_2000_CLDLOW_ANN.nc\n",
      "CLDMED, marc, 1850\n",
      "  Written marc_1850_CLDMED_ANN.nc\n",
      "CLDMED, marc, 2000\n",
      "  Written marc_2000_CLDMED_ANN.nc\n",
      "CLDMED, mam3, 1850\n",
      "  Written mam3_1850_CLDMED_ANN.nc\n",
      "CLDMED, mam3, 2000\n",
      "  Written mam3_2000_CLDMED_ANN.nc\n",
      "CLDMED, mam7, 2000\n",
      "  Written mam7_2000_CLDMED_ANN.nc\n",
      "CLDHGH, marc, 1850\n",
      "  Written marc_1850_CLDHGH_ANN.nc\n",
      "CLDHGH, marc, 2000\n",
      "  Written marc_2000_CLDHGH_ANN.nc\n",
      "CLDHGH, mam3, 1850\n",
      "  Written mam3_1850_CLDHGH_ANN.nc\n",
      "CLDHGH, mam3, 2000\n",
      "  Written mam3_2000_CLDHGH_ANN.nc\n",
      "CLDHGH, mam7, 2000\n",
      "  Written mam7_2000_CLDHGH_ANN.nc\n",
      "TGCLDLWP, marc, 1850\n",
      "  Written marc_1850_TGCLDLWP_ANN.nc\n",
      "TGCLDLWP, marc, 2000\n",
      "  Written marc_2000_TGCLDLWP_ANN.nc\n",
      "TGCLDLWP, mam3, 1850\n",
      "  Written mam3_1850_TGCLDLWP_ANN.nc\n",
      "TGCLDLWP, mam3, 2000\n",
      "  Written mam3_2000_TGCLDLWP_ANN.nc\n",
      "TGCLDLWP, mam7, 2000\n",
      "  Written mam7_2000_TGCLDLWP_ANN.nc\n",
      "TGCLDIWP, marc, 1850\n",
      "  Written marc_1850_TGCLDIWP_ANN.nc\n",
      "TGCLDIWP, marc, 2000\n",
      "  Written marc_2000_TGCLDIWP_ANN.nc\n",
      "TGCLDIWP, mam3, 1850\n",
      "  Written mam3_1850_TGCLDIWP_ANN.nc\n",
      "TGCLDIWP, mam3, 2000\n",
      "  Written mam3_2000_TGCLDIWP_ANN.nc\n",
      "TGCLDIWP, mam7, 2000\n",
      "  Written mam7_2000_TGCLDIWP_ANN.nc\n",
      "TGCLDCWP, marc, 1850\n",
      "  Written marc_1850_TGCLDCWP_ANN.nc\n",
      "TGCLDCWP, marc, 2000\n",
      "  Written marc_2000_TGCLDCWP_ANN.nc\n",
      "TGCLDCWP, mam3, 1850\n",
      "  Written mam3_1850_TGCLDCWP_ANN.nc\n",
      "TGCLDCWP, mam3, 2000\n",
      "  Written mam3_2000_TGCLDCWP_ANN.nc\n",
      "TGCLDCWP, mam7, 2000\n",
      "  Written mam7_2000_TGCLDCWP_ANN.nc\n",
      "FSNTOA, marc, 1850\n",
      "  Written marc_1850_FSNTOA_ANN.nc\n",
      "FSNTOA, marc, 2000\n",
      "  Written marc_2000_FSNTOA_ANN.nc\n",
      "FSNTOA, mam3, 1850\n",
      "  Written mam3_1850_FSNTOA_ANN.nc\n",
      "FSNTOA, mam3, 2000\n",
      "  Written mam3_2000_FSNTOA_ANN.nc\n",
      "FSNTOA, mam7, 2000\n",
      "  Written mam7_2000_FSNTOA_ANN.nc\n",
      "FSNTOANOA, marc, 1850\n",
      "  Written marc_1850_FSNTOANOA_ANN.nc\n",
      "FSNTOANOA, marc, 2000\n",
      "  Written marc_2000_FSNTOANOA_ANN.nc\n",
      "FSNTOA_d1, mam3, 1850\n",
      "  Written mam3_1850_FSNTOA_d1_ANN.nc\n",
      "FSNTOA_d1, mam3, 2000\n",
      "  Written mam3_2000_FSNTOA_d1_ANN.nc\n",
      "FSNTOA_d1, mam7, 2000\n",
      "  Written mam7_2000_FSNTOA_d1_ANN.nc\n",
      "FSNS, marc, 1850\n",
      "  Written marc_1850_FSNS_ANN.nc\n",
      "FSNS, marc, 2000\n",
      "  Written marc_2000_FSNS_ANN.nc\n",
      "FSNS, mam3, 1850\n",
      "  Written mam3_1850_FSNS_ANN.nc\n",
      "FSNS, mam3, 2000\n",
      "  Written mam3_2000_FSNS_ANN.nc\n",
      "FSNS, mam7, 2000\n",
      "  Written mam7_2000_FSNS_ANN.nc\n",
      "FSNSNOA, marc, 1850\n",
      "  Written marc_1850_FSNSNOA_ANN.nc\n",
      "FSNSNOA, marc, 2000\n",
      "  Written marc_2000_FSNSNOA_ANN.nc\n",
      "FSNS_d1, mam3, 1850\n",
      "  Written mam3_1850_FSNS_d1_ANN.nc\n",
      "FSNS_d1, mam3, 2000\n",
      "  Written mam3_2000_FSNS_d1_ANN.nc\n",
      "FSNS_d1, mam7, 2000\n",
      "  Written mam7_2000_FSNS_d1_ANN.nc\n",
      "CRF, marc, 1850\n",
      "  Written marc_1850_CRF_ANN.nc\n",
      "CRF, marc, 2000\n",
      "  Written marc_2000_CRF_ANN.nc\n",
      "SWCF_d1, mam3, 1850\n",
      "  Written mam3_1850_SWCF_d1_ANN.nc\n",
      "SWCF_d1, mam3, 2000\n",
      "  Written mam3_2000_SWCF_d1_ANN.nc\n",
      "SWCF_d1, mam7, 2000\n",
      "  Written mam7_2000_SWCF_d1_ANN.nc\n",
      "LWCF, marc, 1850\n",
      "  Written marc_1850_LWCF_ANN.nc\n",
      "LWCF, marc, 2000\n",
      "  Written marc_2000_LWCF_ANN.nc\n",
      "LWCF, mam3, 1850\n",
      "  Written mam3_1850_LWCF_ANN.nc\n",
      "LWCF, mam3, 2000\n",
      "  Written mam3_2000_LWCF_ANN.nc\n",
      "LWCF, mam7, 2000\n",
      "  Written mam7_2000_LWCF_ANN.nc\n",
      "FSNTOACNOA, marc, 1850\n",
      "  Written marc_1850_FSNTOACNOA_ANN.nc\n",
      "FSNTOACNOA, marc, 2000\n",
      "  Written marc_2000_FSNTOACNOA_ANN.nc\n",
      "FSNTOAC_d1, mam3, 1850\n",
      "  Written mam3_1850_FSNTOAC_d1_ANN.nc\n",
      "FSNTOAC_d1, mam3, 2000\n",
      "  Written mam3_2000_FSNTOAC_d1_ANN.nc\n",
      "FSNTOAC_d1, mam7, 2000\n",
      "  Written mam7_2000_FSNTOAC_d1_ANN.nc\n",
      "Mon Nov  6 16:32:25 +08 2017\n"
     ]
    }
   ],
   "source": [
    "variable_list = ['SUL_LDG', 'pSUL_LDG', 'OC_LDG', 'BC_LDG', 'MOS_LDG', 'MBS_LDG',  # MARC column loadings\n",
    "                 'BURDENSO4', 'BURDENPOM', 'BURDENBC',  # MAM column loadings\n",
    "                 'TAU_tot', 'AEROD_v',  # AOD in MARC, MAM\n",
    "                 'CDNUMC',  # Vertically-integrated CDNC\n",
    "                 'CLDTOT', 'CLDLOW', 'CLDMED', 'CLDHGH',  # Cloud fraction\n",
    "                 'TGCLDLWP', 'TGCLDIWP', 'TGCLDCWP',  # Grid-box average water path\n",
    "                 'FSNTOA', 'FSNTOANOA', 'FSNTOA_d1',  # SW flux at TOA, including clean-sky for MARC, MAM\n",
    "                 'FSNS', 'FSNSNOA', 'FSNS_d1',  # SW flux at surface, including clean-sky for MAM, MAM\n",
    "                 'CRF', 'SWCF_d1',  # SW cloud radiative effect in MARC, MAM\n",
    "                 'LWCF',  # LW cloud radiative effect \n",
    "                 'FSNTOACNOA', 'FSNTOAC_d1',  # SW clear-sky clean-sky flux at TOA in MARC, MAM\n",
    "                ]\n",
    "for variable in variable_list:\n",
    "    for model in ['marc', 'mam3', 'mam7']:\n",
    "        for year in ['1850', '2000']:\n",
    "            # Check if input file exists\n",
    "            in_filename = '{}/p17c_{}_{}.cam.h0.{}.nc'.format(in_dir, model, year, variable)\n",
    "            if os.path.isfile(in_filename):\n",
    "                print('{}, {}, {}'.format(variable, model, year))\n",
    "                # Calculate annual mean using NCO (with years starting in January)\n",
    "                annual_filename = '{}/{}_{}_{}_ANN.nc'.format(out_dir, model, year, variable)\n",
    "                ! ncra -O --mro -d time,,,12,12 {in_filename} {annual_filename}\n",
    "                print('  Written {}'.format(annual_filename.split('/')[-1]))\n",
    "! date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate annual means of land variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSNO, marc, 1850\n",
      "  Written marc_1850_FSNO_ANN.nc\n",
      "FSNO, marc, 2000\n",
      "  Written marc_2000_FSNO_ANN.nc\n",
      "FSNO, mam3, 1850\n",
      "  Written mam3_1850_FSNO_ANN.nc\n",
      "FSNO, mam3, 2000\n",
      "  Written mam3_2000_FSNO_ANN.nc\n",
      "FSNO, mam7, 2000\n",
      "  Written mam7_2000_FSNO_ANN.nc\n",
      "SNOBCMSL, marc, 1850\n",
      "  Written marc_1850_SNOBCMSL_ANN.nc\n",
      "SNOBCMSL, marc, 2000\n",
      "  Written marc_2000_SNOBCMSL_ANN.nc\n",
      "SNOBCMSL, mam3, 1850\n",
      "  Written mam3_1850_SNOBCMSL_ANN.nc\n",
      "SNOBCMSL, mam3, 2000\n",
      "  Written mam3_2000_SNOBCMSL_ANN.nc\n",
      "SNOBCMSL, mam7, 2000\n",
      "  Written mam7_2000_SNOBCMSL_ANN.nc\n",
      "Mon Nov  6 16:32:31 +08 2017\n"
     ]
    }
   ],
   "source": [
    "variable_list = ['FSNO',  # fraction of ground covered by snow\n",
    "                 'SNOBCMSL',  # mass of BC in top layer of snow\n",
    "                ]\n",
    "for variable in variable_list:\n",
    "    for model in ['marc', 'mam3', 'mam7']:\n",
    "        for year in ['1850', '2000']:\n",
    "            # Check if input file exists\n",
    "            in_filename = '{}/p17c_{}_{}.clm2.h0.{}.nc'.format(in_dir, model, year, variable)\n",
    "            if os.path.isfile(in_filename):\n",
    "                print('{}, {}, {}'.format(variable, model, year))\n",
    "                # Calculate annual mean using NCO (with years starting in January)\n",
    "                annual_filename = '{}/{}_{}_{}_ANN.nc'.format(out_dir, model, year, variable)\n",
    "                ! ncra -O --mro -d time,,,12,12 {in_filename} {annual_filename}\n",
    "                print('  Written {}'.format(annual_filename.split('/')[-1]))\n",
    "! date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data on specific atmosphere model levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCN3, marc, 1850, ml30\n",
      "  Selecting data for model level 30\n",
      "  Renaming variable to CCN3_ml30\n",
      "  Calculating annual mean\n",
      "  Written marc_1850_CCN3_ml30_ANN.nc\n",
      "  Removing temp_marc_1850_CCN3_ml30.nc\n",
      "CCN3, marc, 1850, ml19\n",
      "  Selecting data for model level 19\n",
      "  Renaming variable to CCN3_ml19\n",
      "  Calculating annual mean\n",
      "  Written marc_1850_CCN3_ml19_ANN.nc\n",
      "  Removing temp_marc_1850_CCN3_ml19.nc\n",
      "CCN3, marc, 2000, ml30\n",
      "  Selecting data for model level 30\n",
      "  Renaming variable to CCN3_ml30\n",
      "  Calculating annual mean\n",
      "  Written marc_2000_CCN3_ml30_ANN.nc\n",
      "  Removing temp_marc_2000_CCN3_ml30.nc\n",
      "CCN3, marc, 2000, ml19\n",
      "  Selecting data for model level 19\n",
      "  Renaming variable to CCN3_ml19\n",
      "  Calculating annual mean\n",
      "  Written marc_2000_CCN3_ml19_ANN.nc\n",
      "  Removing temp_marc_2000_CCN3_ml19.nc\n",
      "CCN3, mam3, 1850, ml30\n",
      "  Selecting data for model level 30\n",
      "  Renaming variable to CCN3_ml30\n",
      "  Calculating annual mean\n",
      "  Written mam3_1850_CCN3_ml30_ANN.nc\n",
      "  Removing temp_mam3_1850_CCN3_ml30.nc\n",
      "CCN3, mam3, 1850, ml19\n",
      "  Selecting data for model level 19\n",
      "  Renaming variable to CCN3_ml19\n",
      "  Calculating annual mean\n",
      "  Written mam3_1850_CCN3_ml19_ANN.nc\n",
      "  Removing temp_mam3_1850_CCN3_ml19.nc\n",
      "CCN3, mam3, 2000, ml30\n",
      "  Selecting data for model level 30\n",
      "  Renaming variable to CCN3_ml30\n",
      "  Calculating annual mean\n",
      "  Written mam3_2000_CCN3_ml30_ANN.nc\n",
      "  Removing temp_mam3_2000_CCN3_ml30.nc\n",
      "CCN3, mam3, 2000, ml19\n",
      "  Selecting data for model level 19\n",
      "  Renaming variable to CCN3_ml19\n",
      "  Calculating annual mean\n",
      "  Written mam3_2000_CCN3_ml19_ANN.nc\n",
      "  Removing temp_mam3_2000_CCN3_ml19.nc\n",
      "CCN3, mam7, 2000, ml30\n",
      "  Selecting data for model level 30\n",
      "  Renaming variable to CCN3_ml30\n",
      "  Calculating annual mean\n",
      "  Written mam7_2000_CCN3_ml30_ANN.nc\n",
      "  Removing temp_mam7_2000_CCN3_ml30.nc\n",
      "CCN3, mam7, 2000, ml19\n",
      "  Selecting data for model level 19\n",
      "  Renaming variable to CCN3_ml19\n",
      "  Calculating annual mean\n",
      "  Written mam7_2000_CCN3_ml19_ANN.nc\n",
      "  Removing temp_mam7_2000_CCN3_ml19.nc\n",
      "Mon Nov  6 16:33:10 +08 2017\n"
     ]
    }
   ],
   "source": [
    "variable_list = ['CCN3', ]\n",
    "for variable in variable_list:\n",
    "    for model in ['marc', 'mam3', 'mam7']:\n",
    "        for year in ['1850', '2000']:\n",
    "            # Check if input file exists\n",
    "            in_filename = '{}/p17c_{}_{}.cam.h0.{}.nc'.format(in_dir, model, year, variable)\n",
    "            if os.path.isfile(in_filename):  # there is no mam7_1850 simulation\n",
    "                # Loop over model levels of interest\n",
    "                for level in [30, 19]:  # 30 is bottom level; 19 is ~525hPa\n",
    "                    print('{}, {}, {}, ml{}'.format(variable, model, year, level))\n",
    "                    # Select data for model level using CDO\n",
    "                    print('  Selecting data for model level {}'.format(level))\n",
    "                    level_filename = '{}/temp_{}_{}_{}_ml{}.nc'.format(out_dir, model, year, variable, level)\n",
    "                    ! cdo -s sellevidx,{level} {in_filename} {level_filename}\n",
    "                    # Rename variable using NCO\n",
    "                    print('  Renaming variable to {}_ml{}'.format(variable, level))\n",
    "                    ! ncrename -v {variable},{variable}_ml{level} {level_filename} >/dev/null 2>/dev/null\n",
    "                    # Calculate annual mean using NCO (with years starting in January)\n",
    "                    print('  Calculating annual mean')\n",
    "                    annual_filename = '{}/{}_{}_{}_ml{}_ANN.nc'.format(out_dir, model, year, variable, level)\n",
    "                    ! ncra -O --mro -d time,,,12,12 {level_filename} {annual_filename}\n",
    "                    print('  Written {}'.format(annual_filename.split('/')[-1]))\n",
    "                    # Remove temporary file\n",
    "                    for filename in [level_filename, ]:\n",
    "                        print('  Removing {}'.format(filename.split('/')[-1]))\n",
    "                        os.remove(filename)\n",
    "! date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate column loadings from MARC mass mixing ratios\n",
    "- This is to facilitate comparison with MAM. Although MARC diagnoses the column loading for total sulphate, column loadings are not available for total OC and total BC.\n",
    "- Regarding the calculation of the mass in each level, the following reference is helpful:  http://nco.sourceforge.net/nco.html#Left-hand-casting. A description of the hybrid vertical coordinate system can be found here: http://www.cesm.ucar.edu/models/atm-cam/docs/usersguide/node25.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year = 1850\n",
      "  Copying surface pressure file\n",
      "  Calculating mass of air in each model level\n",
      "  aerosol = OC\n",
      "    Copying the file for mOC\n",
      "    Appending mass_air\n",
      "    Calculating the mass of OC in each model level\n",
      "    Summing over levels\n",
      "    Renaming variable to cOC_LDG\n",
      "    Setting units and long_name\n",
      "    Calculating annual mean\n",
      "    Written marc_1850_cOC_LDG_ANN.nc\n",
      "    Removing temp_marc_1850_mOC.nc\n",
      "    Removing temp_marc_1850_mass_OC.nc\n",
      "    Removing temp_marc_1850_column_OC.nc\n",
      "  aerosol = OIM\n",
      "    Copying the file for mOIM\n",
      "    Appending mass_air\n",
      "    Calculating the mass of OIM in each model level\n",
      "    Summing over levels\n",
      "    Renaming variable to cOIM_LDG\n",
      "    Setting units and long_name\n",
      "    Calculating annual mean\n",
      "    Written marc_1850_cOIM_LDG_ANN.nc\n",
      "    Removing temp_marc_1850_mOIM.nc\n",
      "    Removing temp_marc_1850_mass_OIM.nc\n",
      "    Removing temp_marc_1850_column_OIM.nc\n",
      "  aerosol = BIM\n",
      "    Copying the file for mBIM\n",
      "    Appending mass_air\n",
      "    Calculating the mass of BIM in each model level\n",
      "    Summing over levels\n",
      "    Renaming variable to cBIM_LDG\n",
      "    Setting units and long_name\n",
      "    Calculating annual mean\n",
      "    Written marc_1850_cBIM_LDG_ANN.nc\n",
      "    Removing temp_marc_1850_mBIM.nc\n",
      "    Removing temp_marc_1850_mass_BIM.nc\n",
      "    Removing temp_marc_1850_column_BIM.nc\n",
      "  Removing temp_marc_1850_PS.nc\n",
      "  Removing temp_marc_1850_mass_air.nc\n",
      "  Removing temp_marc_1850.nco\n",
      "year = 2000\n",
      "  Copying surface pressure file\n",
      "  Calculating mass of air in each model level\n",
      "  aerosol = OC\n",
      "    Copying the file for mOC\n",
      "    Appending mass_air\n",
      "    Calculating the mass of OC in each model level\n",
      "    Summing over levels\n",
      "    Renaming variable to cOC_LDG\n",
      "    Setting units and long_name\n",
      "    Calculating annual mean\n",
      "    Written marc_2000_cOC_LDG_ANN.nc\n",
      "    Removing temp_marc_2000_mOC.nc\n",
      "    Removing temp_marc_2000_mass_OC.nc\n",
      "    Removing temp_marc_2000_column_OC.nc\n",
      "  aerosol = OIM\n",
      "    Copying the file for mOIM\n",
      "    Appending mass_air\n",
      "    Calculating the mass of OIM in each model level\n",
      "    Summing over levels\n",
      "    Renaming variable to cOIM_LDG\n",
      "    Setting units and long_name\n",
      "    Calculating annual mean\n",
      "    Written marc_2000_cOIM_LDG_ANN.nc\n",
      "    Removing temp_marc_2000_mOIM.nc\n",
      "    Removing temp_marc_2000_mass_OIM.nc\n",
      "    Removing temp_marc_2000_column_OIM.nc\n",
      "  aerosol = BIM\n",
      "    Copying the file for mBIM\n",
      "    Appending mass_air\n",
      "    Calculating the mass of BIM in each model level\n",
      "    Summing over levels\n",
      "    Renaming variable to cBIM_LDG\n",
      "    Setting units and long_name\n",
      "    Calculating annual mean\n",
      "    Written marc_2000_cBIM_LDG_ANN.nc\n",
      "    Removing temp_marc_2000_mBIM.nc\n",
      "    Removing temp_marc_2000_mass_BIM.nc\n",
      "    Removing temp_marc_2000_column_BIM.nc\n",
      "  Removing temp_marc_2000_PS.nc\n",
      "  Removing temp_marc_2000_mass_air.nc\n",
      "  Removing temp_marc_2000.nco\n",
      "Mon Nov  6 16:39:11 +08 2017\n"
     ]
    }
   ],
   "source": [
    "# Calculate column loadings from mass mixing ratios\n",
    "for year in ['1850', '2000']:  # loop over emission years\n",
    "    print('year = {}'.format(year))\n",
    "    # Copy the surface pressure file - necessary for decoding of the hybrid coordinates\n",
    "    print('  Copying surface pressure file')\n",
    "    in_filename = '{}/p17c_marc_{}.cam.h0.PS.nc'.format(in_dir, year)\n",
    "    ps_filename = '{}/temp_marc_{}_PS.nc'.format(out_dir, year)\n",
    "    shutil.copy2(in_filename, ps_filename)\n",
    "    # Create file containing NCO commands for calculation of air mass in each model level\n",
    "    nco_filename = '{}/temp_marc_{}.nco'.format(out_dir, year)\n",
    "    nco_file = open(nco_filename, 'w')\n",
    "    nco_file.writelines(['*P_bnds[time,ilev,lat,lon]=hyai*P0+hybi*PS;\\n',  # pressures at bounds\n",
    "                         '*P_delta[time,lev,lat,lon]=P_bnds(:,1:30,:,:)-P_bnds(:,0:29,:,:);\\n',  # deltas\n",
    "                         'mass_air=P_delta/9.807;'])  # mass of air\n",
    "    nco_file.close()\n",
    "    # Calculate mass of air in each model level\n",
    "    print('  Calculating mass of air in each model level')\n",
    "    mass_air_filename = '{}/temp_marc_{}_mass_air.nc'.format(out_dir, year)\n",
    "    ! ncap2 -O -v -S {nco_filename} {ps_filename} {mass_air_filename}\n",
    "    # Loop over mass mixing ratios for different aerosol components\n",
    "    for aerosol in ['OC', 'OIM', 'BIM']:  # OC is included for validation purposes - see next cell\n",
    "        print('  aerosol = {}'.format(aerosol))\n",
    "        # Copy the mass mixing ratio file\n",
    "        print('    Copying the file for m{}'.format(aerosol))\n",
    "        in_filename = '{}/p17c_marc_{}.cam.h0.m{}.nc'.format(in_dir, year, aerosol)\n",
    "        mmr_filename = '{}/temp_marc_{}_m{}.nc'.format(out_dir, year, aerosol)\n",
    "        shutil.copy2(in_filename, mmr_filename)\n",
    "        # Append the mass of air in each model level\n",
    "        print('    Appending mass_air')\n",
    "        ! ncks -A {mass_air_filename} {mmr_filename}\n",
    "        # Calculate the mass of the aerosol\n",
    "        print('    Calculating the mass of {} in each model level'.format(aerosol))\n",
    "        mass_aerosol_filename = '{}/temp_marc_{}_mass_{}.nc'.format(out_dir, year, aerosol)\n",
    "        ! ncap2 -O -s 'mass_{aerosol}=mass_air*m{aerosol}' {mmr_filename} {mass_aerosol_filename}\n",
    "        # Sum over levels to calculate column loading (and exclude unwanted variables)\n",
    "        print('    Summing over levels')\n",
    "        column_filename = '{}/temp_marc_{}_column_{}.nc'.format(out_dir, year, aerosol)\n",
    "        ! ncwa -O -x -v mass_air,m{aerosol} -a lev -y sum {mass_aerosol_filename} {column_filename}\n",
    "        # Rename variable\n",
    "        print('    Renaming variable to c{}_LDG'.format(aerosol))\n",
    "        ! ncrename -v mass_{aerosol},c{aerosol}_LDG {column_filename} >/dev/null 2>/dev/null\n",
    "        # Set units and long_name\n",
    "        print('    Setting units and long_name')\n",
    "        ! ncatted -a 'units',c{aerosol}_LDG,o,c,'kg/m2' {column_filename}\n",
    "        ! ncatted -a 'long_name',c{aerosol}_LDG,o,c,'{aerosol} column loading' {column_filename}\n",
    "        # Calculate annual mean (with years starting in January)\n",
    "        print('    Calculating annual mean')\n",
    "        annual_filename = '{}/marc_{}_c{}_LDG_ANN.nc'.format(out_dir, year, aerosol)\n",
    "        ! ncra -O --mro -d time,,,12,12 {column_filename} {annual_filename}\n",
    "        print('    Written {}'.format(annual_filename.split('/')[-1]))\n",
    "        # Remove three temporary files\n",
    "        for filename in [mmr_filename, mass_aerosol_filename, column_filename]:\n",
    "            print('    Removing {}'.format(filename.split('/')[-1]))\n",
    "            os.remove(filename)\n",
    "    # Remove another two temporary files\n",
    "    for filename in [ps_filename, mass_air_filename, nco_filename]:\n",
    "            print('  Removing {}'.format(filename.split('/')[-1]))\n",
    "            os.remove(filename)\n",
    "! date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date     Time   Level Gridsize    Miss    Diff : S Z  Max_Absdiff Max_Reldiff : Parameter name\n",
      "    16 : 0001-07-16 22:00:00       0    13824       0   13824 : F F   1.8680e-08   0.0043520 : OC_LDG     \n",
      "    28 : 0002-07-16 22:00:00       0    13824       0   13824 : F F   1.7920e-08   0.0033875 : OC_LDG     \n",
      "    40 : 0003-07-16 22:00:00       0    13824       0   13824 : F F   2.2142e-08   0.0034263 : OC_LDG     \n",
      "    52 : 0004-07-16 22:00:00       0    13824       0   13824 : F F   2.0513e-08   0.0037291 : OC_LDG     \n",
      "    64 : 0005-07-16 22:00:00       0    13824       0   13824 : F F   2.2773e-08   0.0037233 : OC_LDG     \n",
      "    76 : 0006-07-16 22:00:00       0    13824       0   13824 : F F   2.0662e-08   0.0039365 : OC_LDG     \n",
      "    88 : 0007-07-16 22:00:00       0    13824       0   13824 : F F   1.9976e-08   0.0037408 : OC_LDG     \n",
      "   100 : 0008-07-16 22:00:00       0    13824       0   13824 : F F   2.2041e-08   0.0038573 : OC_LDG     \n",
      "   112 : 0009-07-16 22:00:00       0    13824       0   13824 : F F   2.6660e-08   0.0043534 : OC_LDG     \n",
      "   124 : 0010-07-16 22:00:00       0    13824       0   13824 : F F   1.9852e-08   0.0033552 : OC_LDG     \n",
      "   136 : 0011-07-16 22:00:00       0    13824       0   13824 : F F   1.9518e-08   0.0032689 : OC_LDG     \n",
      "   148 : 0012-07-16 22:00:00       0    13824       0   13824 : F F   1.9910e-08   0.0031571 : OC_LDG     \n",
      "   160 : 0013-07-16 22:00:00       0    13824       0   13824 : F F   2.5326e-08   0.0040345 : OC_LDG     \n",
      "   172 : 0014-07-16 22:00:00       0    13824       0   13824 : F F   2.4279e-08   0.0044787 : OC_LDG     \n",
      "   184 : 0015-07-16 22:00:00       0    13824       0   13824 : F F   2.0370e-08   0.0032296 : OC_LDG     \n",
      "   196 : 0016-07-16 22:00:00       0    13824       0   13824 : F F   1.9202e-08   0.0032223 : OC_LDG     \n",
      "   208 : 0017-07-16 22:00:00       0    13824       0   13824 : F F   1.7970e-08   0.0030263 : OC_LDG     \n",
      "   220 : 0018-07-16 22:00:00       0    13824       0   13824 : F F   1.9617e-08   0.0033901 : OC_LDG     \n",
      "   232 : 0019-07-16 22:00:00       0    13824       0   13824 : F F   1.7446e-08   0.0036935 : OC_LDG     \n",
      "   244 : 0020-07-16 22:00:00       0    13824       0   13824 : F F   1.6583e-08   0.0025758 : OC_LDG     \n",
      "   256 : 0021-07-16 22:00:00       0    13824       0   13824 : F F   1.5374e-08   0.0031978 : OC_LDG     \n",
      "   268 : 0022-07-16 22:00:00       0    13824       0   13824 : F F   1.9021e-08   0.0028473 : OC_LDG     \n",
      "   280 : 0023-07-16 22:00:00       0    13824       0   13824 : F F   2.3440e-08   0.0036320 : OC_LDG     \n",
      "   292 : 0024-07-16 22:00:00       0    13824       0   13824 : F F   1.7279e-08   0.0034595 : OC_LDG     \n",
      "   304 : 0025-07-16 22:00:00       0    13824       0   13824 : F F   1.8309e-08   0.0032554 : OC_LDG     \n",
      "   316 : 0026-07-16 22:00:00       0    13824       0   13824 : F F   2.0346e-08   0.0034018 : OC_LDG     \n",
      "   328 : 0027-07-16 22:00:00       0    13824       0   13824 : F F   1.8497e-08   0.0030537 : OC_LDG     \n",
      "   340 : 0028-07-16 22:00:00       0    13824       0   13824 : F F   1.6972e-08   0.0035486 : OC_LDG     \n",
      "   352 : 0029-07-16 22:00:00       0    13824       0   13824 : F F   2.2272e-08   0.0037766 : OC_LDG     \n",
      "   364 : 0030-07-16 22:00:00       0    13824       0   13824 : F F   2.4819e-08   0.0039871 : OC_LDG     \n",
      "   376 : 0031-07-16 22:00:00       0    13824       0   13824 : F F   2.0455e-08   0.0032542 : OC_LDG     \n",
      "   388 : 0032-07-16 22:00:00       0    13824       0   13824 : F F   2.0627e-08   0.0037408 : OC_LDG     \n",
      "  32 of 388 records differ\n",
      "  0 of 388 records differ more than 0.001\n",
      "cdo diffn: Processed 886206 values from 32 variables over 64 timesteps ( 0.09s )\n",
      "  Removing temp_marc_1850_cOC_LDG_ANN.nc\n",
      "               Date     Time   Level Gridsize    Miss    Diff : S Z  Max_Absdiff Max_Reldiff : Parameter name\n",
      "    16 : 0001-07-16 22:00:00       0    13824       0   13824 : F F   1.6707e-08   0.0036111 : OC_LDG     \n",
      "    28 : 0002-07-16 22:00:00       0    13824       0   13824 : F F   1.8736e-08   0.0029704 : OC_LDG     \n",
      "    40 : 0003-07-16 22:00:00       0    13824       0   13824 : F F   2.1273e-08   0.0032537 : OC_LDG     \n",
      "    52 : 0004-07-16 22:00:00       0    13824       0   13824 : F F   1.7069e-08   0.0027961 : OC_LDG     \n",
      "    64 : 0005-07-16 22:00:00       0    13824       0   13824 : F F   1.6487e-08   0.0033589 : OC_LDG     \n",
      "    76 : 0006-07-16 22:00:00       0    13824       0   13824 : F F   1.7793e-08   0.0034047 : OC_LDG     \n",
      "    88 : 0007-07-16 22:00:00       0    13824       0   13824 : F F   1.8747e-08   0.0029713 : OC_LDG     \n",
      "   100 : 0008-07-16 22:00:00       0    13824       0   13824 : F F   1.7960e-08   0.0038876 : OC_LDG     \n",
      "   112 : 0009-07-16 22:00:00       0    13824       0   13824 : F F   1.7181e-08   0.0035497 : OC_LDG     \n",
      "   124 : 0010-07-16 22:00:00       0    13824       0   13824 : F F   1.6984e-08   0.0038519 : OC_LDG     \n",
      "   136 : 0011-07-16 22:00:00       0    13824       0   13824 : F F   1.7805e-08   0.0032660 : OC_LDG     \n",
      "   148 : 0012-07-16 22:00:00       0    13824       0   13824 : F F   2.2781e-08   0.0034432 : OC_LDG     \n",
      "   160 : 0013-07-16 22:00:00       0    13824       0   13824 : F F   1.5394e-08   0.0035602 : OC_LDG     \n",
      "   172 : 0014-07-16 22:00:00       0    13824       0   13824 : F F   1.4387e-08   0.0026496 : OC_LDG     \n",
      "   184 : 0015-07-16 22:00:00       0    13824       0   13824 : F F   1.5646e-08   0.0030676 : OC_LDG     \n",
      "   196 : 0016-07-16 22:00:00       0    13824       0   13824 : F F   1.8803e-08   0.0032195 : OC_LDG     \n",
      "   208 : 0017-07-16 22:00:00       0    13824       0   13824 : F F   1.5704e-08   0.0029909 : OC_LDG     \n",
      "   220 : 0018-07-16 22:00:00       0    13824       0   13824 : F F   1.5839e-08   0.0037267 : OC_LDG     \n",
      "   232 : 0019-07-16 22:00:00       0    13824       0   13824 : F F   2.0219e-08   0.0036644 : OC_LDG     \n",
      "   244 : 0020-07-16 22:00:00       0    13824       0   13824 : F F   1.4081e-08   0.0029280 : OC_LDG     \n",
      "   256 : 0021-07-16 22:00:00       0    13824       0   13824 : F F   1.9743e-08   0.0028092 : OC_LDG     \n",
      "   268 : 0022-07-16 22:00:00       0    13824       0   13824 : F F   1.5901e-08   0.0034801 : OC_LDG     \n",
      "   280 : 0023-07-16 22:00:00       0    13824       0   13824 : F F   1.7091e-08   0.0031632 : OC_LDG     \n",
      "   292 : 0024-07-16 22:00:00       0    13824       0   13824 : F F   1.7592e-08   0.0034473 : OC_LDG     \n",
      "   304 : 0025-07-16 22:00:00       0    13824       0   13824 : F F   1.7532e-08   0.0033852 : OC_LDG     \n",
      "   316 : 0026-07-16 22:00:00       0    13824       0   13824 : F F   1.4760e-08   0.0037670 : OC_LDG     \n",
      "   328 : 0027-07-16 22:00:00       0    13824       0   13824 : F F   2.0217e-08   0.0031503 : OC_LDG     \n",
      "   340 : 0028-07-16 22:00:00       0    13824       0   13824 : F F   1.7305e-08   0.0032052 : OC_LDG     \n",
      "   352 : 0029-07-16 22:00:00       0    13824       0   13824 : F F   1.9433e-08   0.0027304 : OC_LDG     \n",
      "   364 : 0030-07-16 22:00:00       0    13824       0   13824 : F F   1.7809e-08   0.0032860 : OC_LDG     \n",
      "   376 : 0031-07-16 22:00:00       0    13824       0   13824 : F F   1.7248e-08   0.0035413 : OC_LDG     \n",
      "   388 : 0032-07-16 22:00:00       0    13824       0   13824 : F F   1.3613e-08   0.0029042 : OC_LDG     \n",
      "  32 of 388 records differ\n",
      "  0 of 388 records differ more than 0.001\n",
      "cdo diffn: Processed 886206 values from 32 variables over 64 timesteps ( 0.10s )\n",
      "  Removing temp_marc_2000_cOC_LDG_ANN.nc\n",
      "Mon Nov  6 16:39:12 +08 2017\n"
     ]
    }
   ],
   "source": [
    "# Compare cOC_LDG (calculated above) with standard OC_LDG\n",
    "for year in ['1850', '2000']:\n",
    "    # Input files\n",
    "    in_filename_1 = '{}/marc_{}_OC_LDG_ANN.nc'.format(out_dir, year)\n",
    "    in_filename_2 = '{}/marc_{}_cOC_LDG_ANN.nc'.format(out_dir, year)\n",
    "    # Rename cOC_LDG to OC_LDG to enable comparison\n",
    "    temp_filename = '{}/temp_marc_{}_cOC_LDG_ANN.nc'.format(out_dir, year)\n",
    "    ! ncrename -O -v cOC_LDG,OC_LDG {in_filename_2} {temp_filename} >/dev/null 2>/dev/null\n",
    "    # Compare using CDO\n",
    "    ! cdo diffv {in_filename_1} {temp_filename}\n",
    "    # Remove temporary file\n",
    "    for filename in [temp_filename, ]:\n",
    "            print('  Removing {}'.format(filename.split('/')[-1]))\n",
    "            os.remove(filename)\n",
    "! date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In results above, the maximum relative difference is less than 1%. This shows that the calculation of the column loadings is working as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive additional variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctOC_LDG=OC_LDG+cOIM_LDG, marc, 1850\n",
      "  Written marc_1850_ctOC_LDG_ANN.nc\n",
      "  Removing temp_marc_1850_merge_ANN.nc\n",
      "ctOC_LDG=OC_LDG+cOIM_LDG, marc, 2000\n",
      "  Written marc_2000_ctOC_LDG_ANN.nc\n",
      "  Removing temp_marc_2000_merge_ANN.nc\n",
      "ctBC_LDG=BC_LDG+cBIM_LDG, marc, 1850\n",
      "  Written marc_1850_ctBC_LDG_ANN.nc\n",
      "  Removing temp_marc_1850_merge_ANN.nc\n",
      "ctBC_LDG=BC_LDG+cBIM_LDG, marc, 2000\n",
      "  Written marc_2000_ctBC_LDG_ANN.nc\n",
      "  Removing temp_marc_2000_merge_ANN.nc\n",
      "cFNTOA=FSNTOA+LWCF, marc, 1850\n",
      "  Written marc_1850_cFNTOA_ANN.nc\n",
      "  Removing temp_marc_1850_merge_ANN.nc\n",
      "cFNTOA=FSNTOA+LWCF, marc, 2000\n",
      "  Written marc_2000_cFNTOA_ANN.nc\n",
      "  Removing temp_marc_2000_merge_ANN.nc\n",
      "cFNTOA=FSNTOA+LWCF, mam3, 1850\n",
      "  Written mam3_1850_cFNTOA_ANN.nc\n",
      "  Removing temp_mam3_1850_merge_ANN.nc\n",
      "cFNTOA=FSNTOA+LWCF, mam3, 2000\n",
      "  Written mam3_2000_cFNTOA_ANN.nc\n",
      "  Removing temp_mam3_2000_merge_ANN.nc\n",
      "cDRE=FSNTOA-FSNTOANOA, marc, 1850\n",
      "  Written marc_1850_cDRE_ANN.nc\n",
      "  Removing temp_marc_1850_merge_ANN.nc\n",
      "cDRE=FSNTOA-FSNTOANOA, marc, 2000\n",
      "  Written marc_2000_cDRE_ANN.nc\n",
      "  Removing temp_marc_2000_merge_ANN.nc\n",
      "cDRE=FSNTOA-FSNTOA_d1, mam3, 1850\n",
      "  Written mam3_1850_cDRE_ANN.nc\n",
      "  Removing temp_mam3_1850_merge_ANN.nc\n",
      "cDRE=FSNTOA-FSNTOA_d1, mam3, 2000\n",
      "  Written mam3_2000_cDRE_ANN.nc\n",
      "  Removing temp_mam3_2000_merge_ANN.nc\n",
      "cDRE=FSNTOA-FSNTOA_d1, mam7, 2000\n",
      "  Written mam7_2000_cDRE_ANN.nc\n",
      "  Removing temp_mam7_2000_merge_ANN.nc\n",
      "cDREsurf=FSNS-FSNSNOA, marc, 1850\n",
      "  Written marc_1850_cDREsurf_ANN.nc\n",
      "  Removing temp_marc_1850_merge_ANN.nc\n",
      "cDREsurf=FSNS-FSNSNOA, marc, 2000\n",
      "  Written marc_2000_cDREsurf_ANN.nc\n",
      "  Removing temp_marc_2000_merge_ANN.nc\n",
      "cDREsurf=FSNS-FSNS_d1, mam3, 1850\n",
      "  Written mam3_1850_cDREsurf_ANN.nc\n",
      "  Removing temp_mam3_1850_merge_ANN.nc\n",
      "cDREsurf=FSNS-FSNS_d1, mam3, 2000\n",
      "  Written mam3_2000_cDREsurf_ANN.nc\n",
      "  Removing temp_mam3_2000_merge_ANN.nc\n",
      "cDREsurf=FSNS-FSNS_d1, mam7, 2000\n",
      "  Written mam7_2000_cDREsurf_ANN.nc\n",
      "  Removing temp_mam7_2000_merge_ANN.nc\n",
      "cAAA=cDRE-cDREsurf, marc, 1850\n",
      "  Written marc_1850_cAAA_ANN.nc\n",
      "  Removing temp_marc_1850_merge_ANN.nc\n",
      "cAAA=cDRE-cDREsurf, marc, 2000\n",
      "  Written marc_2000_cAAA_ANN.nc\n",
      "  Removing temp_marc_2000_merge_ANN.nc\n",
      "cAAA=cDRE-cDREsurf, mam3, 1850\n",
      "  Written mam3_1850_cAAA_ANN.nc\n",
      "  Removing temp_mam3_1850_merge_ANN.nc\n",
      "cAAA=cDRE-cDREsurf, mam3, 2000\n",
      "  Written mam3_2000_cAAA_ANN.nc\n",
      "  Removing temp_mam3_2000_merge_ANN.nc\n",
      "cAAA=cDRE-cDREsurf, mam7, 2000\n",
      "  Written mam7_2000_cAAA_ANN.nc\n",
      "  Removing temp_mam7_2000_merge_ANN.nc\n",
      "Tue Nov  7 16:08:12 +08 2017\n"
     ]
    }
   ],
   "source": [
    "derived_variable_dict = {'ctOC_LDG=OC_LDG+cOIM_LDG': ['marc',],  # total OC loading\n",
    "                         'ctBC_LDG=BC_LDG+cBIM_LDG': ['marc',],  # total BC loading\n",
    "                         'cFNTOA=FSNTOA+LWCF': ['marc', 'mam3'],  # net (SW + LW) radiative effect\n",
    "                         'cDRE=FSNTOA-FSNTOANOA': ['marc',],  # direct radiative effect at TOA\n",
    "                         'cDRE=FSNTOA-FSNTOA_d1': ['mam3', 'mam7'],\n",
    "                         'cDREsurf=FSNS-FSNSNOA': ['marc',],  # direct radiative effect at surface\n",
    "                         'cDREsurf=FSNS-FSNS_d1': ['mam3', 'mam7'],\n",
    "                         'cAAA=cDRE-cDREsurf': ['marc', 'mam3', 'mam7'],  # absorption by aerosols in atmosphere\n",
    "                        }\n",
    "for derived_variable, model_list in derived_variable_dict.items():\n",
    "    for model in model_list:\n",
    "        if model == 'mam7':\n",
    "            year_list = ['2000',]\n",
    "        else:\n",
    "            year_list = ['1850', '2000']\n",
    "        for year in year_list:\n",
    "            print('{}, {}, {}'.format(derived_variable, model, year))\n",
    "            # Merge input files\n",
    "            variable_list = re.split('\\=|\\+|\\-', derived_variable)\n",
    "            in_filename_1 = '{}/{}_{}_{}_ANN.nc'.format(out_dir, model, year, variable_list[1])\n",
    "            in_filename_2 = '{}/{}_{}_{}_ANN.nc'.format(out_dir, model, year, variable_list[2])\n",
    "            merge_filename = '{}/temp_{}_{}_merge_ANN.nc'.format(out_dir, model, year)\n",
    "            ! cdo -s merge {in_filename_1} {in_filename_2} {merge_filename} >/dev/null 2>/dev/null\n",
    "            # Calculate derived variable\n",
    "            out_filename = '{}/{}_{}_{}_ANN.nc'.format(out_dir, model, year, variable_list[0])\n",
    "            ! cdo -s expr,{derived_variable} {merge_filename} {out_filename}\n",
    "            if os.path.isfile(out_filename):\n",
    "                print('  Written {}'.format(out_filename.split('/')[-1]))\n",
    "            # Remove temporary file\n",
    "            for filename in [merge_filename, ]:\n",
    "                print('  Removing {}'.format(filename.split('/')[-1]))\n",
    "                os.remove(filename)\n",
    "! date"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
